{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "import os\n",
    "import threading\n",
    "import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from torch_geometric.loader.link_neighbor_loader import LinkNeighborLoader\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import (\n",
    "                                    HeteroData,\n",
    "                                    Data, \n",
    "                                    Batch\n",
    "                                 )   \n",
    "from torch_geometric.nn import (\n",
    "                                GATv2Conv,\n",
    "                                SAGPooling,\n",
    "                                global_add_pool,\n",
    "                                HeteroConv,\n",
    "                                Linear,\n",
    "                                to_hetero\n",
    "                                )\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score,\n",
    "    roc_auc_score, \n",
    "    precision_recall_curve, \n",
    "    auc, \n",
    "    average_precision_score, \n",
    "    matthews_corrcoef\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed all randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Usage example:\n",
    "seed_everything(29)  # Set the seed to 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict = data.to_dict()\n",
    "fnm = '../prep_data/hetero_graph/hetero_data_dict.pt'\n",
    "data = torch.load(fnm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mdrug\u001b[0m={ node_id=[1007] },\n",
       "  \u001b[1mside_effect\u001b[0m={ node_id=[5587] },\n",
       "  \u001b[1m(drug, known, side_effect)\u001b[0m={ edge_index=[2, 132063] },\n",
       "  \u001b[1m(drug, struct, drug)\u001b[0m={\n",
       "    edge_index=[2, 15844],\n",
       "    edge_attr=[15844]\n",
       "  },\n",
       "  \u001b[1m(drug, word, drug)\u001b[0m={\n",
       "    edge_index=[2, 83865],\n",
       "    edge_attr=[83865]\n",
       "  },\n",
       "  \u001b[1m(drug, target, drug)\u001b[0m={\n",
       "    edge_index=[2, 3363],\n",
       "    edge_attr=[3363]\n",
       "  },\n",
       "  \u001b[1m(drug, se_encoded, drug)\u001b[0m={\n",
       "    edge_index=[2, 65854],\n",
       "    edge_attr=[65854]\n",
       "  },\n",
       "  \u001b[1m(side_effect, name, side_effect)\u001b[0m={\n",
       "    edge_index=[2, 299170],\n",
       "    edge_attr=[299170]\n",
       "  },\n",
       "  \u001b[1m(side_effect, dg_encoded, side_effect)\u001b[0m={\n",
       "    edge_index=[2, 101114],\n",
       "    edge_attr=[101114]\n",
       "  },\n",
       "  \u001b[1m(side_effect, atc, side_effect)\u001b[0m={\n",
       "    edge_index=[2, 26140],\n",
       "    edge_attr=[26140]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Transformation Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_TO_ID_DICT = {}\n",
    "drug_id_mol_graph_tup = []\n",
    "ID_TO_DB_DICT = {}\n",
    "MEDRAID_TO_ID_DICT = {}\n",
    "ID_TO_MEDRAID_DICT = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list = [DB_TO_ID_DICT, ID_TO_DB_DICT, MEDRAID_TO_ID_DICT, ID_TO_MEDRAID_DICT, drug_id_mol_graph_tup]\n",
    "file_names = ['db_to_id.pt', 'id_to_db.pt', 'uml_to_id.pt', 'id_to_uml.pt', 'drug_to_mol.pt']\n",
    "\n",
    "for data_dict, fnm in zip(dict_list, file_names):\n",
    "    full_path = f\"../prep_data/hetero_graph/{fnm}\"\n",
    "    loaded_data = torch.load(full_path)\n",
    "    \n",
    "    if isinstance(data_dict, dict):\n",
    "        data_dict.update(loaded_data)\n",
    "    elif isinstance(data_dict, list):\n",
    "        data_dict.extend(loaded_data)\n",
    "    else:\n",
    "        # If it's neither a dict nor a list, just replace it\n",
    "        index = dict_list.index(data_dict)\n",
    "        dict_list[index] = loaded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variant DV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_similarity_edges = [('drug', 'struct', 'drug'),\n",
    "                           ('drug', 'word', 'drug'),\n",
    "                           ('drug', 'target', 'drug'),\n",
    "                           ('drug', 'se_encoded', 'drug'),\n",
    "                           ('side_effect', 'name', 'side_effect'),\n",
    "                           ('side_effect', 'dg_encoded', 'side_effect'),\n",
    "                           ('side_effect', 'atc', 'side_effect')\n",
    "                            ]\n",
    "for edge in remove_similarity_edges:\n",
    "    del data[edge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mdrug\u001b[0m={ node_id=[1007] },\n",
       "  \u001b[1mside_effect\u001b[0m={ node_id=[5587] },\n",
       "  \u001b[1m(drug, known, side_effect)\u001b[0m={ edge_index=[2, 132063] }\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HeteroData Undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = T.ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecule Featurization Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bond featurization\n",
    "def get_bond_features(bond):\n",
    "    # Simplified list of bond types\n",
    "    permitted_bond_types = [Chem.rdchem.BondType.SINGLE, Chem.rdchem.BondType.DOUBLE, \n",
    "                            Chem.rdchem.BondType.TRIPLE, Chem.rdchem.BondType.AROMATIC, 'Unknown']\n",
    "    bond_type = bond.GetBondType() if bond.GetBondType() in permitted_bond_types else 'Unknown'\n",
    "    \n",
    "    # Features: Bond type, Is in a ring\n",
    "    features = one_of_k_encoding_unk(bond_type, permitted_bond_types) \\\n",
    "               + [bond.IsInRing()]\n",
    "    \n",
    "    return np.array(features, dtype=np.float32)\n",
    "\n",
    "def get_mol_edge_list_and_feat_mtx(mol_graph):\n",
    "    n_features = [(atom.GetIdx(), atom_features(atom)) for atom in mol_graph.GetAtoms()]\n",
    "    n_features.sort() # to make sure that the feature matrix is aligned according to the idx of the atom\n",
    "    _, n_features = zip(*n_features)\n",
    "    # n_features = torch.stack(n_features)\n",
    "    n_features = torch.tensor(n_features, dtype=torch.float32)\n",
    "\n",
    "    edge_list = torch.LongTensor([(b.GetBeginAtomIdx(), b.GetEndAtomIdx()) for b in mol_graph.GetBonds()])\n",
    "    undirected_edge_list = torch.cat([edge_list, edge_list[:, [1, 0]]], dim=0) if len(edge_list) else edge_list \n",
    "\n",
    "    # Extract bond features\n",
    "    bond_features = [get_bond_features(bond) for bond in mol_graph.GetBonds()]\n",
    "    undirected_bond_features = bond_features + bond_features  # duplicate for undirected edges\n",
    "    edge_attr = torch.tensor(undirected_bond_features, dtype=torch.float32)\n",
    "\n",
    "    return undirected_edge_list.T, n_features, edge_attr \n",
    "\n",
    "\n",
    "def one_of_k_encoding_unk(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))\n",
    "\n",
    "def all_of_k_encoding_unk(x, allowable_set):\n",
    "    enc = np.zeros(len(allowable_set))\n",
    "    for idx, side_eff_id in enumerate(allowable_set):\n",
    "        if side_eff_id in x:\n",
    "            enc[idx] = 1\n",
    "    return enc\n",
    "    \n",
    "def atom_features(atom,\n",
    "                explicit_H=True,\n",
    "                use_chirality=False):\n",
    "\n",
    "    results = one_of_k_encoding_unk(\n",
    "        atom.GetSymbol(),\n",
    "        ['C','N','O', 'S','F','Si','P', 'Cl','Br','Mg','Na','Ca','Fe','As','Al','I','B','V','K','Tl',\n",
    "            'Yb','Sb','Sn','Ag','Pd','Co','Se','Ti','Zn','H', 'Li','Ge','Cu','Au','Ni','Cd','In',\n",
    "            'Mn','Zr','Cr','Pt','Hg','Pb','Unknown'\n",
    "        ]) + [atom.GetDegree()/10, atom.GetImplicitValence(), \n",
    "                atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \\\n",
    "                one_of_k_encoding_unk(atom.GetHybridization(), [\n",
    "                Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.\n",
    "                                    SP3D, Chem.rdchem.HybridizationType.SP3D2\n",
    "                ]) + [atom.GetIsAromatic()]\n",
    "    # In case of explicit hydrogen(QM8, QM9), avoid calling `GetTotalNumHs`\n",
    "    if explicit_H:\n",
    "        results = results + [atom.GetTotalNumHs()]\n",
    "\n",
    "    if use_chirality:\n",
    "        try:\n",
    "            results = results + one_of_k_encoding_unk(\n",
    "            atom.GetProp('_CIPCode'),\n",
    "            ['R', 'S']) + [atom.HasProp('_ChiralityPossible')]\n",
    "        except:\n",
    "            results = results + [False, False\n",
    "                            ] + [atom.HasProp('_ChiralityPossible')]\n",
    "\n",
    "    results = np.array(results).astype(np.float32)\n",
    "\n",
    "    return results #torch.from_numpy(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Molecule Featurization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:19: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "/home/mayank/miniconda3/envs/dsn/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3277.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOL_EDGE_LIST_FEAT_MTX = {DB_TO_ID_DICT[drug_id]: get_mol_edge_list_and_feat_mtx(mol) \n",
    "                                for drug_id, mol in drug_id_mol_graph_tup}\n",
    "len(MOL_EDGE_LIST_FEAT_MTX.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([57, 55]), torch.Size([16, 6]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOL_EDGE_LIST_FEAT_MTX[998][1].shape, MOL_EDGE_LIST_FEAT_MTX[998][2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kfold_data(data, k=10, shuffle=True, num_neighbors=[10, 4], batch_size=64):\n",
    "    kf = KFold(n_splits=k, shuffle=shuffle)\n",
    "    kf.get_n_splits()\n",
    "    train_val_data_X = data['drug', 'known', 'side_effect'].edge_index.T.numpy()\n",
    "    for train_index, test_index in kf.split(train_val_data_X):\n",
    "        train_index_, valid_index_ = train_test_split(train_index, test_size=0.1)\n",
    "        train_set = train_index_\n",
    "        valid_set = valid_index_\n",
    "        \n",
    "        train_data_cv = copy.deepcopy(data)\n",
    "        train_data_cv['drug', 'known', 'side_effect'].edge_index = torch.tensor(train_val_data_X[train_set].T)\n",
    "        train_data_cv['side_effect', 'rev_known', 'drug'].edge_index = torch.tensor(train_val_data_X[train_set].T)[[1, 0]]\n",
    "    \n",
    "        val_data_cv = copy.deepcopy(data)\n",
    "        val_data_cv['drug', 'known', 'side_effect'].edge_index = torch.tensor(train_val_data_X[valid_set].T)\n",
    "        val_data_cv['side_effect', 'rev_known', 'drug'].edge_index = torch.tensor(train_val_data_X[valid_set].T)[[1, 0]]\n",
    "    \n",
    "        \n",
    "        \n",
    "        test_data_cv = copy.deepcopy(data)\n",
    "        test_data_cv['drug', 'known', 'side_effect'].edge_index = torch.tensor(train_val_data_X[test_index].T)\n",
    "        test_data_cv['side_effect', 'rev_known', 'drug'].edge_index = torch.tensor(train_val_data_X[test_index].T)[[1, 0]]\n",
    "        \n",
    "        # use RandomLinkSplit to get disjoint train ratio an other pyg transforms\n",
    "        transform = T.RandomLinkSplit(\n",
    "            num_val=0.0,\n",
    "            num_test=0.0,\n",
    "            disjoint_train_ratio=0.3236238313900354,\n",
    "            neg_sampling_ratio=0.0,\n",
    "            add_negative_train_samples=False,\n",
    "            edge_types=('drug', 'known', 'side_effect'),\n",
    "            rev_edge_types=('side_effect', 'rev_known', 'drug'), \n",
    "        )\n",
    "        train_cv, _, _ = transform(train_data_cv)\n",
    "        \n",
    "        transform = T.RandomLinkSplit(\n",
    "            num_val=0.0,\n",
    "            num_test=0.0,\n",
    "            disjoint_train_ratio=0.99,\n",
    "            neg_sampling_ratio=1.0,\n",
    "            add_negative_train_samples=True,\n",
    "            edge_types=('drug', 'known', 'side_effect'),\n",
    "            rev_edge_types=('side_effect', 'rev_known', 'drug'), \n",
    "        )\n",
    "        \n",
    "        val_cv, _, _ = transform(val_data_cv)\n",
    "       \n",
    "\n",
    "        test_cv, _, _ = transform(test_data_cv)\n",
    "        # Define seed edges:\n",
    "        edge_label_index = train_cv['drug', 'known', 'side_effect'].edge_label_index\n",
    "        edge_label = train_cv['drug', 'known', 'side_effect'].edge_label\n",
    "\n",
    "        train_loader = LinkNeighborLoader(\n",
    "            data=train_cv,\n",
    "            num_neighbors=num_neighbors,\n",
    "            neg_sampling_ratio=1.0,\n",
    "            edge_label_index=((\"drug\", \"known\", \"side_effect\"), edge_label_index),\n",
    "            edge_label=edge_label,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            # disjoint=True,\n",
    "        )\n",
    "        \n",
    "        edge_label_index = val_cv['drug', 'known', 'side_effect'].edge_label_index\n",
    "        edge_label = val_cv['drug', 'known', 'side_effect'].edge_label\n",
    "        # num_neighbors is a dictionary, it uses the specified number for each edge type\n",
    "        val_loader = LinkNeighborLoader(\n",
    "            data=val_cv,\n",
    "            num_neighbors=num_neighbors,\n",
    "            edge_label_index=((\"drug\", \"known\", \"side_effect\"), edge_label_index),\n",
    "            edge_label=edge_label,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        edge_label_index = test_cv['drug', 'known', 'side_effect'].edge_label_index\n",
    "        edge_label = test_cv['drug', 'known', 'side_effect'].edge_label\n",
    "\n",
    "        test_loader = LinkNeighborLoader(\n",
    "            data=test_cv,\n",
    "            num_neighbors=num_neighbors,\n",
    "            edge_label_index= ((\"drug\", \"known\", \"side_effect\"), edge_label_index), \n",
    "            edge_label=edge_label,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False\n",
    "        )\n",
    "        yield train_loader, val_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MHGNN Hetero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroMHGNN(nn.Module):\n",
    "    def __init__(self, metadata, in_channels, hidden_dims, heads, use_edge_attr=None):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.norms = nn.ModuleDict()\n",
    "        self.skips = nn.ModuleDict()\n",
    "        self.final_norms = nn.ModuleDict()\n",
    "        \n",
    "        # Define which edge types should use edge attributes\n",
    "        if use_edge_attr is None:\n",
    "            use_edge_attr = {edge_type: False for edge_type in metadata[1]}\n",
    "        \n",
    "        for i, (out_dim, head) in enumerate(zip(hidden_dims, heads)):\n",
    "            conv_dict = {}\n",
    "            for edge_type in metadata[1]:\n",
    "                src, _, dst = edge_type\n",
    "                if i == 0:\n",
    "                    in_channels = in_channels\n",
    "                else:\n",
    "                    in_channels = hidden_dims[i-1] * heads[i-1]\n",
    "                \n",
    "                if use_edge_attr[edge_type]:\n",
    "                    conv_dict[edge_type] = GATv2Conv(in_channels, out_dim, heads=head, add_self_loops=False, edge_dim=1)\n",
    "                else:\n",
    "                    conv_dict[edge_type] = GATv2Conv(in_channels, out_dim, heads=head, add_self_loops=False)\n",
    "            \n",
    "            self.convs.append(HeteroConv(conv_dict, aggr='sum'))\n",
    "            \n",
    "            for node_type in metadata[0]:\n",
    "                self.norms[f'{node_type}_{i}'] = nn.LayerNorm(out_dim * head)\n",
    "                if i == 0:\n",
    "                    self.skips[f'{node_type}_{i}'] = Linear(in_channels, out_dim * head)\n",
    "                else:\n",
    "                    self.skips[f'{node_type}_{i}'] = Linear(hidden_dims[i-1] * heads[i-1], out_dim * head)\n",
    "        \n",
    "        self.node_types = metadata[0]\n",
    "        for node_type in metadata[0]:\n",
    "            self.final_norms[f'{node_type}'] = nn.LayerNorm(out_dim * head *len(heads))\n",
    "        \n",
    "        # Initialize skips with xavier init\n",
    "        for skip in self.skips.values():\n",
    "            nn.init.xavier_uniform_(skip.weight)\n",
    "            nn.init.zeros_(skip.bias)\n",
    "\n",
    "    def forward(self, x_dict, edge_index_dict, edge_attr_dict):\n",
    "        x_repr_dict = {node_type: [] for node_type in self.node_types}\n",
    "        # edge_attr_dict = {key: value.to(torch.float32) for key, value in edge_attr_dict.items()}\n",
    "\n",
    "        \n",
    "        for i, conv in enumerate(self.convs):\n",
    "            skip_x = {}\n",
    "            for node_type in self.node_types:\n",
    "                skip_x[node_type] = self.skips[f'{node_type}_{i}'](x_dict[node_type])\n",
    "            \n",
    "            x_dict_new = conv(x_dict, edge_index_dict, edge_attr_dict)\n",
    "            \n",
    "            for node_type in self.node_types:\n",
    "                # skip_x = self.skips[f'{node_type}_{i}'](x_dict[node_type])\n",
    "                x = x_dict_new[node_type]\n",
    "                x = self.norms[f'{node_type}_{i}'](x) + skip_x[node_type]\n",
    "                x = self.norms[f'{node_type}_{i}'](x)\n",
    "                x = F.elu(x)\n",
    "                x_repr_dict[node_type].append(x)\n",
    "                x_dict[node_type] = x\n",
    "        \n",
    "        # Concatenate all representations for each node type\n",
    "        for node_type in self.node_types:\n",
    "            x_repr_dict[node_type] = self.final_norms[f'{node_type}'](torch.cat(x_repr_dict[node_type], dim=1))\n",
    "        \n",
    "        return x_repr_dict\n",
    "\n",
    "# Specify which edge types should use edge attributes\n",
    "use_edge_attr = {\n",
    "    ('drug', 'known', 'side_effect'): False,\n",
    "    ('drug', 'struct', 'drug'): True,\n",
    "    ('drug', 'word', 'drug'): True,\n",
    "    ('drug', 'target', 'drug'): True,\n",
    "    ('drug', 'se_encoded', 'drug'): True,\n",
    "    ('side_effect', 'name', 'side_effect'): True,\n",
    "    ('side_effect', 'dg_encoded', 'side_effect'): True,\n",
    "    ('side_effect', 'atc', 'side_effect'): True,\n",
    "    ('side_effect', 'rev_known', 'drug'): False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MHGNN - Outer HGNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MHGNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, heads):\n",
    "        super().__init__()\n",
    "        self.GATLayers = nn.ModuleList()\n",
    "        self.norms = nn.ModuleList() \n",
    "        self.skips = nn.ModuleList()\n",
    "        for i, (out_dim, head) in enumerate(zip(hidden_dims, heads)):\n",
    "            self.GATLayers.append(GATv2Conv(input_dim, out_dim, heads=head, add_self_loops=False, name=f'GATLayer{i}'))\n",
    "            self.norms.append(nn.LayerNorm(out_dim * head))\n",
    "            self.skips.append(nn.Linear(input_dim, out_dim * head))\n",
    "            input_dim = out_dim * head      \n",
    "        \n",
    "        # # # initialize skips with xavier init\n",
    "        for skip in self.skips:\n",
    "            nn.init.xavier_uniform_(skip.weight)\n",
    "            nn.init.zeros_(skip.bias)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x_repr = []\n",
    "        for idx, (layer, skip, norm) in enumerate(zip(self.GATLayers, self.skips, self.norms)): # norm, self.norms\n",
    "            skip_x = skip(x)\n",
    "            x = layer(x, edge_index)\n",
    "            x = norm(x) + skip_x  # Add skip connection\n",
    "            x = norm(x)     # Apply normalization\n",
    "            x = F.elu(x)    # Apply activation\n",
    "            x_repr.append(x)\n",
    "            # x = F.elu(norm(x))\n",
    "            # x += skip_x\n",
    "            # x_repr.append(F.elu(x))\n",
    "            # if idx < len(self.GATLayers) - 1:\n",
    "            #     x = F.elu(x) # norm(x)\n",
    "        x_repr = torch.cat(x_repr, dim=1)\n",
    "        return x_repr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DVModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrugInterView_Block(nn.Module):\n",
    "    def __init__(self, n_heads, in_features, head_out_feats):\n",
    "        super().__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.in_features = in_features\n",
    "        self.out_features = head_out_feats\n",
    "\n",
    "        self.feature_conv = GATv2Conv(in_features, head_out_feats, n_heads, edge_dim=6)\n",
    "\n",
    "        self.readout = SAGPooling(n_heads * head_out_feats, min_score=-1)\n",
    "\n",
    "    def forward(self, mol_data):\n",
    "        mol_data.x = self.feature_conv(mol_data.x, mol_data.edge_index, mol_data.edge_attr)\n",
    "        mol_data_att_x, att_edge_index, att_edge_attr, h_att_batch, att_perm, h_att_scores = self.readout(mol_data.x, mol_data.edge_index, batch=mol_data.batch)\n",
    "\n",
    "        mol_data_global_graph_emb = global_add_pool(mol_data_att_x, h_att_batch)\n",
    "\n",
    "        return mol_data, mol_data_global_graph_emb, h_att_scores, h_att_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalDrugMolEmb(nn.Module):\n",
    "    def __init__(self, in_features, heads_out_feat_params, blocks_params):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.n_blocks = len(blocks_params)\n",
    "\n",
    "        self.inital_norm = nn.LayerNorm(self.in_features)\n",
    "\n",
    "        self.blocks = nn.ModuleList()\n",
    "        self.net_norms = nn.ModuleList()\n",
    "\n",
    "        for i, (head_out_feats, n_heads) in enumerate(zip(heads_out_feat_params, blocks_params)):\n",
    "            block = DrugInterView_Block(n_heads, in_features, head_out_feats)\n",
    "            self.blocks.append(block)\n",
    "            self.net_norms.append(nn.LayerNorm(head_out_feats * n_heads))\n",
    "            in_features = head_out_feats * n_heads\n",
    "       \n",
    "    def forward(self, mol_data):\n",
    "        repr_mol = []\n",
    "        mol_data.x = self.inital_norm(mol_data.x)\n",
    "        attention_weights = []\n",
    "        attention_batch = []\n",
    "        for idx, (block, norm) in enumerate(zip(self.blocks, self.net_norms)):\n",
    "            mol_data, mol_data_global_graph_emb, mol_data_att_x, h_att_batch = block(mol_data)\n",
    "            attention_weights.append(mol_data_att_x)\n",
    "            attention_batch.append((mol_data.batch, h_att_batch))\n",
    "            repr_mol.append(mol_data_global_graph_emb)\n",
    "            if idx < len(self.blocks) - 1:\n",
    "                mol_data.x = F.elu(norm(mol_data.x))\n",
    "        # concat all the global graph embeddings\n",
    "        mol_data_global_graph_emb = torch.cat(repr_mol, dim=1)\n",
    "        return mol_data_global_graph_emb, attention_weights, attention_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DVModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, gnn_model, classifier_model, use_node_features=False, node_feature_mode=\"no\"):\n",
    "        super().__init__()\n",
    "        # Instantiate node embeddings:\n",
    "        self.seff_emb = torch.nn.Embedding(data[\"side_effect\"].num_nodes, hidden_channels)\n",
    "        # DV for Drug\n",
    "        self.drug_emb = FinalDrugMolEmb(in_features=55, heads_out_feat_params=[64, 64], blocks_params=[3, 3])\n",
    "        outer_emb_dim = 2 * 64 * 3\n",
    "        self.inital_norm_outer_drug = nn.LayerNorm(outer_emb_dim)\n",
    "        # self.inital_norm_outer_se = nn.LayerNorm(outer_emb_dim)\n",
    "        # Instantiate Outer GNNs\n",
    "        self.gnn = gnn_model # outer message passing\n",
    "        self.use_node_features = use_node_features\n",
    "        self.node_feature_mode = node_feature_mode  # combine, feat\n",
    "        if use_node_features:\n",
    "            self.drug_feat_layernorm = torch.nn.LayerNorm(data[\"drug\"].num_features)\n",
    "            self.drug_lin = torch.nn.Linear(data[\"drug\"].num_features, hidden_channels)\n",
    "        # Instantiate classifier:\n",
    "        self.classifier = classifier_model\n",
    "        \n",
    "        torch.nn.init.xavier_uniform_(self.seff_emb.weight)\n",
    "        \n",
    "    def __create_graph_data(self, drug_ids, device):\n",
    "        drug_ids_ = drug_ids.cpu().numpy().astype(int).tolist()\n",
    "        final_data = []\n",
    "        for id in drug_ids_:\n",
    "            _ = MOL_EDGE_LIST_FEAT_MTX[id]\n",
    "            final_data.append(Data(x= _[1]  , edge_index=_[0], edge_attr=_[2]))\n",
    "        return Batch.from_data_list(final_data).to(device)        \n",
    "       \n",
    "    \n",
    "    def forward(self, data: HeteroData) -> Tensor:\n",
    "        if self.use_node_features:\n",
    "            if self.node_feature_mode==\"feat\":\n",
    "                x_dict = {\n",
    "                    \"drug\": self.drug_lin(self.drug_feat_layernorm(data[\"drug\"].x)),\n",
    "                    \"side_effect\": self.seff_emb(data[\"side_effect\"].node_id)\n",
    "                }\n",
    "        else:\n",
    "            drug_list_of_graph_data = self.__create_graph_data(data[\"drug\"].node_id, data[\"drug\"].node_id.device)\n",
    "            \n",
    "            drug_dv, attention_weights, h_att_batch = self.drug_emb(drug_list_of_graph_data)\n",
    "            if self.node_feature_mode==\"combined\":\n",
    "                drug_dv += self.drug_lin(self.drug_feat_layernorm(data[\"drug\"].x))\n",
    "            \n",
    "            # layer normalization of input features for outer gnn:\n",
    "            x_dict = {\n",
    "                \"drug\":  self.inital_norm_outer_drug(drug_dv),\n",
    "                \"side_effect\": self.seff_emb(data[\"side_effect\"].node_id)\n",
    "            }\n",
    "\n",
    "        # `x_dict` holds feature matrices of all node types\n",
    "        # `edge_index_dict` holds all edge indices of all edge types\n",
    "        # x_dict = self.gnn(x_dict, data.edge_index_dict, data.edge_attr_dict)\n",
    "        # Forward pass\n",
    "        x_dict = self.gnn(x_dict, data.edge_index_dict, data.edge_attr_dict)\n",
    "        pred = self.classifier(\n",
    "            x_dict[\"drug\"],\n",
    "            x_dict[\"side_effect\"],\n",
    "            data[\"drug\", \"known\", \"side_effect\"].edge_label_index,\n",
    "        )\n",
    "\n",
    "        return pred, attention_weights, h_att_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edge Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our final classifier applies the hammard-product between source and destination\n",
    "# node embeddings to derive edge-level predictions:\n",
    "class VanillaClassifier(torch.nn.Module):\n",
    "    def forward(self, x_drug: Tensor, x_se: Tensor, edge_label_index: Tensor) -> Tensor:\n",
    "        # Convert node embeddings to edge-level representations:\n",
    "        edge_feat_drug = x_drug[edge_label_index[0]]\n",
    "        edge_feat_se = x_se[edge_label_index[1]]\n",
    "\n",
    "        # Apply hammard-product to get a prediction per supervision edge:\n",
    "        return (edge_feat_drug * edge_feat_se).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_train_compute(batch, device, model):\n",
    "    # batch = batch.to(device)\n",
    "    pred, _, _ = model(batch)\n",
    "    actual = batch[\"drug\", \"known\", \"side_effect\"].edge_label\n",
    "    return pred, actual\n",
    "\n",
    "# def do_train_compute(batch, device, model):\n",
    "#     # batch = batch.to(device)\n",
    "#     pred = model(batch)\n",
    "#     actual = batch.edge_label\n",
    "#     return pred, actual\n",
    "\n",
    "\n",
    "def evaluate_metrics(probas_pred, ground_truth):\n",
    "    # compute binary classification metrics using sklearn\n",
    "    # convert to numpy array\n",
    "    probas_pred = probas_pred.numpy()\n",
    "    \n",
    "    ground_truth = ground_truth.numpy()\n",
    "    \n",
    "    # convert to binary predictions\n",
    "    binary_pred = np.where(probas_pred > 0.5, 1, 0)\n",
    "\n",
    "    \n",
    "    # compute metrics\n",
    "    accuracy = accuracy_score(ground_truth, binary_pred)\n",
    "    precision = precision_score(ground_truth, binary_pred)\n",
    "    recall = recall_score(ground_truth, binary_pred)\n",
    "    f1 = f1_score(ground_truth, binary_pred)\n",
    "    roc_auc = roc_auc_score(ground_truth, probas_pred)\n",
    "    precision_, recall_, _ = precision_recall_curve(ground_truth, probas_pred)\n",
    "    pr_auc = auc(recall_, precision_)\n",
    "    average_precision = average_precision_score(ground_truth, probas_pred)\n",
    "    return accuracy, precision, recall, f1, roc_auc, pr_auc, average_precision\n",
    "\n",
    "def train_loop(model, model_name, writer, train_loader, val_loader, loss_fn, optimizer, n_epochs, device, scheduler=None, early_stopping_patience=3, early_stopping_counter=0):\n",
    "    early_stop = False\n",
    "    best_val_metrics = -float(\"inf\") #-float(\"inf\")\n",
    "    best_model_path = f\"saved_models/{model_name}/best_model.pth\"\n",
    "    # make best_model_path parent directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(best_model_path), exist_ok=True)\n",
    "    \n",
    "    print(\"Starting training loop at\", datetime.today().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "    \n",
    "    total_train_val_steps = len(train_loader) + len(val_loader)\n",
    "    epoch_progress_bar = tqdm.notebook.tqdm(range(1, (total_train_val_steps*n_epochs)+1), desc=\"MiniBatches\")\n",
    "    epoch = 0\n",
    "    for _ in epoch_progress_bar:\n",
    "        epoch += 1\n",
    "        start_time = time.time()\n",
    "        train_loss = 0\n",
    "        val_loss = 0\n",
    "        train_probas_pred = []\n",
    "        train_ground_truth = []\n",
    "        val_probas_pred = []\n",
    "        val_ground_truth = []\n",
    "        print(\"Epoch\", epoch)\n",
    "        \n",
    "        model.train()\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            batch = batch.to(device)\n",
    "            lr = optimizer.param_groups[0]['lr']\n",
    "            optimizer.zero_grad()\n",
    "            out, actual = do_train_compute(batch, device, model)\n",
    "            pred = torch.sigmoid(out)\n",
    "            train_probas_pred.append(pred.detach().cpu())\n",
    "            train_ground_truth.append(actual.detach().cpu())\n",
    "            loss = loss_fn(out, actual)\n",
    "            loss.backward()\n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Adjust max_norm as needed\n",
    "\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            epoch_progress_bar.set_postfix_str(f\"Epoch {epoch} - LR {lr:.7f} - Train Batch {idx+1}/{len(train_loader)} - Train loss: {train_loss/(idx+1):.4f}\")\n",
    "            epoch_progress_bar.update()\n",
    "            writer.add_scalar(\"Training Loss MiniBatch\", loss.item(), idx)\n",
    "            batch = batch.to(\"cpu\")\n",
    "            # if scheduler is not None: # cosine annealing scheduler\n",
    "            #     scheduler.step()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        writer.add_scalar(\"Training Loss Epoch\", train_loss, epoch)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_probas_pred = torch.cat(train_probas_pred, dim=0)\n",
    "            train_ground_truth = torch.cat(train_ground_truth, dim=0)\n",
    "            train_accuracy, train_precision, train_recall, train_f1, \\\n",
    "                train_roc_auc, train_pr_auc, train_average_precision = evaluate_metrics(train_probas_pred, train_ground_truth)\n",
    "            writer.add_scalar(\"Training Accuracy\", train_accuracy, epoch)\n",
    "            writer.add_scalar(\"Training Precision\", train_precision, epoch)\n",
    "            writer.add_scalar(\"Training Recall\", train_recall, epoch)\n",
    "            writer.add_scalar(\"Training F1\", train_f1, epoch)\n",
    "            writer.add_scalar(\"Training ROC AUC\", train_roc_auc, epoch)\n",
    "            writer.add_scalar(\"Training PR AUC\", train_pr_auc, epoch)\n",
    "            writer.add_scalar(\"Training Average Precision\", train_average_precision, epoch)\n",
    "\n",
    "            for idx_, batch in enumerate(val_loader):\n",
    "                batch = batch.to(device)\n",
    "                out, actual = do_train_compute(batch, device, model)\n",
    "                pred = torch.sigmoid(out)\n",
    "                val_probas_pred.append(pred.detach().cpu())\n",
    "                val_ground_truth.append(actual.detach().cpu())\n",
    "                loss = loss_fn(out, actual)\n",
    "                val_loss += loss.item()\n",
    "                epoch_progress_bar.set_postfix_str(f\"Epoch {epoch} - LR {lr:.7f} - Val Batch {idx_+1}/{len(val_loader)} - Val loss: {val_loss/(idx+1):.4f}\")\n",
    "                epoch_progress_bar.update()\n",
    "                writer.add_scalar(\"Validation Loss MiniBatch\", loss.item(), idx_)\n",
    "                batch = batch.to(\"cpu\")\n",
    "            val_loss /= len(val_loader)\n",
    "            val_probas_pred = torch.cat(val_probas_pred, dim=0)\n",
    "            val_ground_truth = torch.cat(val_ground_truth, dim=0)\n",
    "            val_accuracy, val_precision, val_recall, val_f1, \\\n",
    "                val_roc_auc, val_pr_auc, val_average_precision = evaluate_metrics(val_probas_pred, val_ground_truth)\n",
    "            \n",
    "            writer.add_scalar(\"Validation Loss Epoch\", val_loss, epoch)\n",
    "            writer.add_scalar(\"Validation Accuracy\", val_accuracy, epoch)\n",
    "            writer.add_scalar(\"Validation Precision\", val_precision, epoch)\n",
    "            writer.add_scalar(\"Validation Recall\", val_recall, epoch)\n",
    "            writer.add_scalar(\"Validation F1\", val_f1, epoch)\n",
    "            writer.add_scalar(\"Validation ROC AUC\", val_roc_auc, epoch)\n",
    "            writer.add_scalar(\"Validation PR AUC\", val_pr_auc, epoch)\n",
    "            writer.add_scalar(\"Validation Average Precision\", val_average_precision, epoch)\n",
    "            \n",
    "            if val_f1 > best_val_metrics:\n",
    "                best_val_metrics = val_f1\n",
    "                early_stopping_counter = 0\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "                print(\"New best model saved!\") \n",
    "            else:\n",
    "                early_stopping_counter += 1\n",
    "                print(\"Early stopping counter:\", early_stopping_counter)\n",
    "                if early_stopping_counter >= early_stopping_patience:\n",
    "                    print(\"Early stopping triggered!\")\n",
    "                    early_stop = True\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(val_f1) #\n",
    "      \n",
    "        \n",
    "        epoch_progress_bar.set_postfix_str(\"Train loss: {:.4f}, Train f1: {:.4f}, Train auc: {:.4f}, Train pr_auc: {:.4f},\\\n",
    "                                            Val loss: {:.4f}, Val f1: {:.4f}, Val auc: {:.4f}, Val pr_auc: {:.4f},\\\n",
    "                                            Best val f1: {:.4f}\".format(train_loss, train_f1, train_roc_auc, train_pr_auc,\\\n",
    "                                            val_loss, val_f1, val_roc_auc, val_pr_auc, best_val_metrics))\n",
    "        epoch_progress_bar.update()\n",
    "        print(\"Epoch Number:\", epoch)   \n",
    "        print(\"Epoch time:\", time.time() - start_time)\n",
    "        print(\"Train loss:\", train_loss)\n",
    "        print(\"Train accuracy:\", train_accuracy)\n",
    "        print(\"Train precision:\", train_precision)\n",
    "        print(\"Train recall:\", train_recall)\n",
    "        print(\"Train f1:\", train_f1)\n",
    "        print(\"Train roc_auc:\", train_roc_auc)\n",
    "        print(\"Train pr_auc:\", train_pr_auc)\n",
    "        print(\"Train average_precision:\", train_average_precision)\n",
    "        \n",
    "        print(\"Val loss:\", val_loss)\n",
    "        print(\"Val accuracy:\", val_accuracy)\n",
    "        print(\"Val precision:\", val_precision)\n",
    "        print(\"Val recall:\", val_recall)\n",
    "        print(\"Val f1:\", val_f1)\n",
    "        print(\"Val roc_auc:\", val_roc_auc)\n",
    "        print(\"Val pr_auc:\", val_pr_auc)\n",
    "        print(\"Val average_precision:\", val_average_precision)\n",
    "        print(\"Best val_f1:\", best_val_metrics)\n",
    "        print()\n",
    "        if early_stop:\n",
    "            break\n",
    "        if epoch == n_epochs:\n",
    "            print(\"Training completed!\")\n",
    "            break\n",
    "    \n",
    "    # load best model \n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Evaluate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrank(y, y_pre):\n",
    "    index = np.argsort(-y_pre)\n",
    "    r_label = y[index]\n",
    "    r_index = np.array(np.where(r_label == 1)) + 1\n",
    "    reci_sum = np.sum(1 / r_index)\n",
    "    reci_rank = np.mean(1 / r_index)\n",
    "    return reci_sum\n",
    "\n",
    "def evaluate_fold(loader, model, device, ret=False):\n",
    "    preds = []\n",
    "    ground_truths = []\n",
    "    model.eval()\n",
    "    for sampled_data in tqdm.tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            sampled_data.to(device)\n",
    "            pred, _, _ = model(sampled_data) \n",
    "            # Applying sigmoid activation function to the predicted values\n",
    "            output_probs = torch.sigmoid(pred)\n",
    "\n",
    "            preds.append(output_probs)\n",
    "            ground_truths.append(sampled_data[\"drug\", \"known\", \"side_effect\"].edge_label)\n",
    "\n",
    "    pred = torch.cat(preds, dim=0).cpu().numpy()\n",
    "    pred_int = (pred>0.5).astype(int)\n",
    "    ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
    "\n",
    "    auc = roc_auc_score(ground_truth, pred)\n",
    "    ap = average_precision_score(ground_truth, pred)\n",
    "    mr = mrank(ground_truth, pred)\n",
    "    f1 = f1_score(ground_truth, pred_int)\n",
    "    mcc = matthews_corrcoef(ground_truth, pred_int)\n",
    "    acc = (pred_int == ground_truth).mean()\n",
    "    precision = precision_score(ground_truth, pred_int)\n",
    "    recall = recall_score(ground_truth, pred_int)\n",
    "    print()\n",
    "    print(f\"Test AUC: {auc:.4f}\")\n",
    "    print(f\"Test AP: {ap:.4f}\")\n",
    "    print(f\"Test F1: {f1:.4f}\")\n",
    "    print(f\"Test Accuracy: {acc:.4f}\")\n",
    "    print(f\"Test Precission: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test MCC: {mcc:.4f}\")\n",
    "    print(f\"Test MR: {mr:.4f}\")\n",
    "    if ret:\n",
    "        return auc, ap, f1, acc, precision, recall, mr, mcc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Wrap CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wrap_cv(data, model_name_, cv_fold=10, shuffle=True, num_neighbors=[10, 4], batch_size=64, n_epochs=10, early_stopping_patience=5):\n",
    "    eval_metrics = []\n",
    "    for i, (train_loader_cv, val_loader_cv,  test_loader_cv) in enumerate(get_kfold_data(data, k=cv_fold,\n",
    "                                                                shuffle=shuffle,\n",
    "                                                                num_neighbors=num_neighbors, \n",
    "                                                                batch_size=batch_size)):\n",
    "        print(f\"Fold {i+1}\")\n",
    "        model_name = f\"{model_name_}/fold{i+1}\"\n",
    "        # Define the log directory where TensorBoard logs will be stored\n",
    "        log_dir = f\"logs/{model_name}/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "        # Create a SummaryWriter\n",
    "        writer = SummaryWriter(log_dir)\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Device: '{device}'\")\n",
    "\n",
    "        # gnn_model = MHGNN(input_dim=384, hidden_dims=[64, 64, 64], heads=[2, 2, 2])\n",
    "\n",
    "        # gnn_model = to_hetero(gnn_model, metadata=data.metadata())\n",
    "\n",
    "        gnn_model = HeteroMHGNN(data.metadata(), in_channels=384, hidden_dims=[64, 64, 64], heads=[2, 2, 2], use_edge_attr=use_edge_attr)\n",
    "        classifier_model = VanillaClassifier()\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = DVModel(hidden_channels=384, gnn_model=gnn_model,\n",
    "                        classifier_model=classifier_model, use_node_features=False)\n",
    "        \n",
    "        model = model.to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.00025062971034390006) #,  weight_decay=0.001)\n",
    "        \n",
    "        # optimizer = torch.optim.SGD(model.parameters(), lr=0.00025062971034390006, weight_decay=0.001)\n",
    "        # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, \n",
    "        #                                                                  T_0=len(train_loader_cv), \n",
    "        #                                                                  T_mult=1, eta_min=1e-5, \n",
    "        #                                                                  verbose=False)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode=\"max\", factor=0.5, patience=2, min_lr=1e-6\n",
    "            )\n",
    "        # scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.96 ** (epoch))\n",
    "    \n",
    "        print(f\"Total Number of Parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "        print(f\"Total Number of Trainable Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "        \n",
    "        model = train_loop(model, model_name, writer, train_loader_cv, val_loader_cv,\n",
    "                             F.binary_cross_entropy_with_logits, optimizer, n_epochs=n_epochs, \n",
    "                             device=device, scheduler=scheduler, early_stopping_patience=early_stopping_patience)\n",
    "\n",
    "        # load best model and store evaluation metrics\n",
    "        model.load_state_dict(torch.load(f'saved_models/{model_name}/best_model.pth'))\n",
    "        auc, ap, f1, acc, precision, recall, mr, mcc = evaluate_fold(test_loader_cv, model, torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), ret=True)\n",
    "        eval_metrics.append([auc, ap, f1, acc, precision, recall, mr, mcc])\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Train CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mdrug\u001b[0m={ node_id=[1007] },\n",
       "  \u001b[1mside_effect\u001b[0m={ node_id=[5587] },\n",
       "  \u001b[1m(drug, known, side_effect)\u001b[0m={ edge_index=[2, 132063] },\n",
       "  \u001b[1m(side_effect, rev_known, drug)\u001b[0m={ edge_index=[2, 132063] }\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Device: 'cuda'\n",
      "Total Number of Parameters: 2744944\n",
      "Total Number of Trainable Parameters: 2744944\n",
      "Starting training loop at 2024-08-05 17:24:26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aeb3c64b2594dc0bdf56864abb4f06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MiniBatches:   0%|          | 0/6740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "New best model saved!\n",
      "Epoch Number: 1\n",
      "Epoch time: 40.29823327064514\n",
      "Train loss: 1.2928061621296139\n",
      "Train accuracy: 0.6899032836752204\n",
      "Train precision: 0.6952407682129826\n",
      "Train recall: 0.6762343030964824\n",
      "Train f1: 0.6856058359527905\n",
      "Train roc_auc: 0.7452964353067086\n",
      "Train pr_auc: 0.7049551082612389\n",
      "Train average_precision: 0.7038764893767748\n",
      "Val loss: 28.02231058284374\n",
      "Val accuracy: 0.5088916934373566\n",
      "Val precision: 0.9532163742690059\n",
      "Val recall: 0.018701239100504818\n",
      "Val f1: 0.036682795093957464\n",
      "Val roc_auc: 0.7369683096670817\n",
      "Val pr_auc: 0.6992310159967932\n",
      "Val average_precision: 0.6992773528720391\n",
      "Best val_f1: 0.036682795093957464\n",
      "\n",
      "Epoch 2\n",
      "New best model saved!\n",
      "Epoch Number: 2\n",
      "Epoch time: 40.98165273666382\n",
      "Train loss: 0.5402394868340575\n",
      "Train accuracy: 0.7926838780126355\n",
      "Train precision: 0.7845174008643566\n",
      "Train recall: 0.807035332657359\n",
      "Train f1: 0.7956170703575548\n",
      "Train roc_auc: 0.866621624965101\n",
      "Train pr_auc: 0.8463757947788898\n",
      "Train average_precision: 0.8464003271641122\n",
      "Val loss: 19.80973701770581\n",
      "Val accuracy: 0.5120468104635154\n",
      "Val precision: 0.8547297297297297\n",
      "Val recall: 0.029027076640660853\n",
      "Val f1: 0.0561473590767865\n",
      "Val roc_auc: 0.7931086999880582\n",
      "Val pr_auc: 0.7393361551437605\n",
      "Val average_precision: 0.7393779249987932\n",
      "Best val_f1: 0.0561473590767865\n",
      "\n",
      "Epoch 3\n",
      "Early stopping counter: 1\n",
      "Epoch Number: 3\n",
      "Epoch time: 40.63744759559631\n",
      "Train loss: 0.45216147386076444\n",
      "Train accuracy: 0.8143475547929179\n",
      "Train precision: 0.8094123066293041\n",
      "Train recall: 0.822322751735434\n",
      "Train f1: 0.8158164548391466\n",
      "Train roc_auc: 0.8912674153964397\n",
      "Train pr_auc: 0.8739752818877919\n",
      "Train average_precision: 0.8740028848619745\n",
      "Val loss: 16.802491434813653\n",
      "Val accuracy: 0.5113010555300597\n",
      "Val precision: 0.8987854251012146\n",
      "Val recall: 0.02547039926571822\n",
      "Val f1: 0.04953698538435791\n",
      "Val roc_auc: 0.8015877824664951\n",
      "Val pr_auc: 0.7479716875630507\n",
      "Val average_precision: 0.7480114606335884\n",
      "Best val_f1: 0.0561473590767865\n",
      "\n",
      "Epoch 4\n",
      "New best model saved!\n",
      "Epoch Number: 4\n",
      "Epoch time: 42.12918758392334\n",
      "Train loss: 0.41519317718366733\n",
      "Train accuracy: 0.8273730598237267\n",
      "Train precision: 0.8215913879630694\n",
      "Train recall: 0.836362218235707\n",
      "Train f1: 0.8289110058942892\n",
      "Train roc_auc: 0.9027180796004255\n",
      "Train pr_auc: 0.8850710301713973\n",
      "Train average_precision: 0.8850886627042068\n",
      "Val loss: 13.264671361320882\n",
      "Val accuracy: 0.5200206516750803\n",
      "Val precision: 0.8024263431542461\n",
      "Val recall: 0.053120697567691604\n",
      "Val f1: 0.09964489400624126\n",
      "Val roc_auc: 0.7957000713557444\n",
      "Val pr_auc: 0.7457726120060202\n",
      "Val average_precision: 0.7458209501740466\n",
      "Best val_f1: 0.09964489400624126\n",
      "\n",
      "Epoch 5\n",
      "New best model saved!\n",
      "Epoch Number: 5\n",
      "Epoch time: 41.777583360672\n",
      "Train loss: 0.37786627703919967\n",
      "Train accuracy: 0.8389946182045083\n",
      "Train precision: 0.8318128029927091\n",
      "Train recall: 0.8498167069651353\n",
      "Train f1: 0.8407183780551323\n",
      "Train roc_auc: 0.9148186481307439\n",
      "Train pr_auc: 0.8975126304222102\n",
      "Train average_precision: 0.8975271128881123\n",
      "Val loss: 12.56716317267764\n",
      "Val accuracy: 0.5348783845800826\n",
      "Val precision: 0.7820037105751392\n",
      "Val recall: 0.09671867829279486\n",
      "Val f1: 0.1721462119665101\n",
      "Val roc_auc: 0.8105708425327414\n",
      "Val pr_auc: 0.7527336037854455\n",
      "Val average_precision: 0.7527830296169142\n",
      "Best val_f1: 0.1721462119665101\n",
      "\n",
      "Epoch 6\n",
      "New best model saved!\n",
      "Epoch Number: 6\n",
      "Epoch time: 39.994288206100464\n",
      "Train loss: 0.37396384801650584\n",
      "Train accuracy: 0.8392091100538179\n",
      "Train precision: 0.8294197848810786\n",
      "Train recall: 0.8540675454332736\n",
      "Train f1: 0.8415632325250738\n",
      "Train roc_auc: 0.915837083281702\n",
      "Train pr_auc: 0.8982812014049173\n",
      "Train average_precision: 0.8982897937468157\n",
      "Val loss: 8.979855724494826\n",
      "Val accuracy: 0.5912689307021569\n",
      "Val precision: 0.8893783651492903\n",
      "Val recall: 0.20846718678292794\n",
      "Val f1: 0.33776373268891163\n",
      "Val roc_auc: 0.8260821541979103\n",
      "Val pr_auc: 0.8057745609959314\n",
      "Val average_precision: 0.8057938964918894\n",
      "Best val_f1: 0.33776373268891163\n",
      "\n",
      "Epoch 7\n",
      "Early stopping counter: 1\n",
      "Epoch Number: 7\n",
      "Epoch time: 43.28467583656311\n",
      "Train loss: 0.35341553679874116\n",
      "Train accuracy: 0.8492317291942906\n",
      "Train precision: 0.8386401452125246\n",
      "Train recall: 0.8648701349348725\n",
      "Train f1: 0.8515532004761357\n",
      "Train roc_auc: 0.9239218789570559\n",
      "Train pr_auc: 0.9101454275031573\n",
      "Train average_precision: 0.9101516532176053\n",
      "Val loss: 8.38425903768429\n",
      "Val accuracy: 0.5362551629187701\n",
      "Val precision: 0.706266318537859\n",
      "Val recall: 0.12413951353832033\n",
      "Val f1: 0.21116315378610462\n",
      "Val roc_auc: 0.8118617630934526\n",
      "Val pr_auc: 0.7511259874593048\n",
      "Val average_precision: 0.7511750617325448\n",
      "Best val_f1: 0.33776373268891163\n",
      "\n",
      "Epoch 8\n",
      "Early stopping counter: 2\n",
      "Epoch Number: 8\n",
      "Epoch time: 40.51309013366699\n",
      "Train loss: 0.362704448420508\n",
      "Train accuracy: 0.8470868107011934\n",
      "Train precision: 0.8339587242026266\n",
      "Train recall: 0.8667420638015756\n",
      "Train f1: 0.8500344220913334\n",
      "Train roc_auc: 0.9205472524155462\n",
      "Train pr_auc: 0.9026400781278191\n",
      "Train average_precision: 0.9026510042502965\n",
      "Val loss: 8.734897920103629\n",
      "Val accuracy: 0.5243804497475907\n",
      "Val precision: 0.8489326765188834\n",
      "Val recall: 0.059316200091785225\n",
      "Val f1: 0.11088471849865954\n",
      "Val roc_auc: 0.8103573860777529\n",
      "Val pr_auc: 0.7573791707148073\n",
      "Val average_precision: 0.7574194248410016\n",
      "Best val_f1: 0.33776373268891163\n",
      "\n",
      "Epoch 9\n",
      "Early stopping counter: 3\n",
      "Epoch Number: 9\n",
      "Epoch time: 40.247135162353516\n",
      "Train loss: 0.3373719655962062\n",
      "Train accuracy: 0.8556664846735824\n",
      "Train precision: 0.8413684683335829\n",
      "Train recall: 0.8766086888698229\n",
      "Train f1: 0.8586271438939608\n",
      "Train roc_auc: 0.9288254551591839\n",
      "Train pr_auc: 0.9119281877028873\n",
      "Train average_precision: 0.9119384995762516\n",
      "Val loss: 7.6471865698785795\n",
      "Val accuracy: 0.5294860027535567\n",
      "Val precision: 0.8768328445747801\n",
      "Val recall: 0.06860945387792565\n",
      "Val f1: 0.12726111938710363\n",
      "Val roc_auc: 0.8201155881973218\n",
      "Val pr_auc: 0.7787728947571613\n",
      "Val average_precision: 0.7788170610903671\n",
      "Best val_f1: 0.33776373268891163\n",
      "\n",
      "Epoch 10\n",
      "Early stopping counter: 4\n",
      "Epoch Number: 10\n",
      "Epoch time: 40.43838691711426\n",
      "Train loss: 0.3078757553846759\n",
      "Train accuracy: 0.8697449496919117\n",
      "Train precision: 0.8550138545645173\n",
      "Train recall: 0.8904921612978707\n",
      "Train f1: 0.8723924505234201\n",
      "Train roc_auc: 0.9386181112536802\n",
      "Train pr_auc: 0.9223095403465228\n",
      "Train average_precision: 0.9223132399882743\n",
      "Val loss: 7.261646218666697\n",
      "Val accuracy: 0.5278223955943093\n",
      "Val precision: 0.8783151326053042\n",
      "Val recall: 0.06459385039008719\n",
      "Val f1: 0.12033771507961954\n",
      "Val roc_auc: 0.8220660373404527\n",
      "Val pr_auc: 0.7834361182297122\n",
      "Val average_precision: 0.7834688599413728\n",
      "Best val_f1: 0.33776373268891163\n",
      "\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [00:24<00:00, 56.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test AUC: 0.8247\n",
      "Test AP: 0.8228\n",
      "Test F1: 0.6551\n",
      "Test Accuracy: 0.7201\n",
      "Test Precission: 0.8534\n",
      "Test Recall: 0.5316\n",
      "Test MCC: 0.4753\n",
      "Test MR: 10.7556\n",
      "Fold 2\n",
      "Device: 'cuda'\n",
      "Total Number of Parameters: 2744944\n",
      "Total Number of Trainable Parameters: 2744944\n",
      "Starting training loop at 2024-08-05 17:31:40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256f569f731c4fde87c0513db9cc395a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MiniBatches:   0%|          | 0/6740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "New best model saved!\n",
      "Epoch Number: 1\n",
      "Epoch time: 38.23499536514282\n",
      "Train loss: 1.3154718109645749\n",
      "Train accuracy: 0.699672412448327\n",
      "Train precision: 0.7044891764517933\n",
      "Train recall: 0.6878948599953202\n",
      "Train f1: 0.696093133385951\n",
      "Train roc_auc: 0.7480504801733219\n",
      "Train pr_auc: 0.7080829727609126\n",
      "Train average_precision: 0.7068647663415635\n",
      "Val loss: 11.480780214182685\n",
      "Val accuracy: 0.544229004130335\n",
      "Val precision: 0.7320891029500302\n",
      "Val recall: 0.13951353832033042\n",
      "Val f1: 0.2343644598631589\n",
      "Val roc_auc: 0.7561502667626501\n",
      "Val pr_auc: 0.719676654334731\n",
      "Val average_precision: 0.7197343102659153\n",
      "Best val_f1: 0.2343644598631589\n",
      "\n",
      "Epoch 2\n",
      "Early stopping counter: 1\n",
      "Epoch Number: 2\n",
      "Epoch time: 41.550193071365356\n",
      "Train loss: 0.5504975961776742\n",
      "Train accuracy: 0.7825832618360502\n",
      "Train precision: 0.780287792047037\n",
      "Train recall: 0.7866781062319632\n",
      "Train f1: 0.7834699188254943\n",
      "Train roc_auc: 0.8575510193907225\n",
      "Train pr_auc: 0.8399591860247834\n",
      "Train average_precision: 0.839991787075716\n",
      "Val loss: 12.072483213599554\n",
      "Val accuracy: 0.5410738871041763\n",
      "Val precision: 0.7465564738292011\n",
      "Val recall: 0.12436897659476824\n",
      "Val f1: 0.21321793863099922\n",
      "Val roc_auc: 0.8122062604345666\n",
      "Val pr_auc: 0.7596396328255666\n",
      "Val average_precision: 0.7596949303959695\n",
      "Best val_f1: 0.2343644598631589\n",
      "\n",
      "Epoch 3\n",
      "Early stopping counter: 2\n",
      "Epoch Number: 3\n",
      "Epoch time: 40.024484634399414\n",
      "Train loss: 0.48432033064954\n",
      "Train accuracy: 0.8052024023087123\n",
      "Train precision: 0.7992505353319058\n",
      "Train recall: 0.8151470244130723\n",
      "Train f1: 0.8071205158898713\n",
      "Train roc_auc: 0.8796563191795187\n",
      "Train pr_auc: 0.8569380346575568\n",
      "Train average_precision: 0.8569572267993342\n",
      "Val loss: 11.753686818432497\n",
      "Val accuracy: 0.5455484167049105\n",
      "Val precision: 0.7594771241830065\n",
      "Val recall: 0.1333180357962368\n",
      "Val f1: 0.22682022252586373\n",
      "Val roc_auc: 0.8219262954974483\n",
      "Val pr_auc: 0.7675921380040049\n",
      "Val average_precision: 0.7676464981083028\n",
      "Best val_f1: 0.2343644598631589\n",
      "\n",
      "Epoch 4\n",
      "New best model saved!\n",
      "Epoch Number: 4\n",
      "Epoch time: 41.44813513755798\n",
      "Train loss: 0.43617263785621474\n",
      "Train accuracy: 0.8189103814055065\n",
      "Train precision: 0.8116781644242863\n",
      "Train recall: 0.8305124405272599\n",
      "Train f1: 0.8209872973650224\n",
      "Train roc_auc: 0.8949478279157738\n",
      "Train pr_auc: 0.8783153240923639\n",
      "Train average_precision: 0.8783416777411299\n",
      "Val loss: 9.684721901126064\n",
      "Val accuracy: 0.5448600275355667\n",
      "Val precision: 0.7291910902696366\n",
      "Val recall: 0.1427260211106012\n",
      "Val f1: 0.2387257724045289\n",
      "Val roc_auc: 0.8225036388691673\n",
      "Val pr_auc: 0.762279764756274\n",
      "Val average_precision: 0.7623450933521116\n",
      "Best val_f1: 0.2387257724045289\n",
      "\n",
      "Epoch 5\n",
      "New best model saved!\n",
      "Epoch Number: 5\n",
      "Epoch time: 39.91838240623474\n",
      "Train loss: 0.4050358110235219\n",
      "Train accuracy: 0.8302199516418376\n",
      "Train precision: 0.8273222776295953\n",
      "Train recall: 0.8346462834412293\n",
      "Train f1: 0.8309681427267963\n",
      "Train roc_auc: 0.90634950291201\n",
      "Train pr_auc: 0.889826058811567\n",
      "Train average_precision: 0.8898521108392535\n",
      "Val loss: 8.547224370157336\n",
      "Val accuracy: 0.5747475906379073\n",
      "Val precision: 0.8843657817109144\n",
      "Val recall: 0.17198256080770996\n",
      "Val f1: 0.28796465277110744\n",
      "Val roc_auc: 0.8299101474165872\n",
      "Val pr_auc: 0.7953828530827933\n",
      "Val average_precision: 0.7954540375197707\n",
      "Best val_f1: 0.28796465277110744\n",
      "\n",
      "Epoch 6\n",
      "Early stopping counter: 1\n",
      "Epoch Number: 6\n",
      "Epoch time: 40.834052324295044\n",
      "Train loss: 0.38548150071479437\n",
      "Train accuracy: 0.8376101708135091\n",
      "Train precision: 0.8308239070620606\n",
      "Train recall: 0.8478667810623196\n",
      "Train f1: 0.839258830341633\n",
      "Train roc_auc: 0.9123057737073288\n",
      "Train pr_auc: 0.8946590128715282\n",
      "Train average_precision: 0.894673951647087\n",
      "Val loss: 8.321449890502013\n",
      "Val accuracy: 0.5366567232675539\n",
      "Val precision: 0.7795275590551181\n",
      "Val recall: 0.10222579164754475\n",
      "Val f1: 0.18074855462014403\n",
      "Val roc_auc: 0.8260097295916358\n",
      "Val pr_auc: 0.7668534893791322\n",
      "Val average_precision: 0.7669223396338579\n",
      "Best val_f1: 0.28796465277110744\n",
      "\n",
      "Epoch 7\n",
      "Early stopping counter: 2\n",
      "Epoch Number: 7\n",
      "Epoch time: 40.03172850608826\n",
      "Train loss: 0.37032033131455544\n",
      "Train accuracy: 0.8425434833476327\n",
      "Train precision: 0.8321673032560603\n",
      "Train recall: 0.8581623898291865\n",
      "Train f1: 0.8449649611212441\n",
      "Train roc_auc: 0.9165220006484931\n",
      "Train pr_auc: 0.8980221820307174\n",
      "Train average_precision: 0.8980284860158522\n",
      "Val loss: 7.38830458236629\n",
      "Val accuracy: 0.5392955484167049\n",
      "Val precision: 0.7837613918806959\n",
      "Val recall: 0.10853602569986233\n",
      "Val f1: 0.19066814471430013\n",
      "Val roc_auc: 0.831249811764473\n",
      "Val pr_auc: 0.776276357910946\n",
      "Val average_precision: 0.776325687541246\n",
      "Best val_f1: 0.28796465277110744\n",
      "\n",
      "Epoch 8\n",
      "Early stopping counter: 3\n",
      "Epoch Number: 8\n",
      "Epoch time: 42.218738079071045\n",
      "Train loss: 0.35012214933696234\n",
      "Train accuracy: 0.8509866625068248\n",
      "Train precision: 0.8384476534296029\n",
      "Train recall: 0.8695109585835739\n",
      "Train f1: 0.8536968258222615\n",
      "Train roc_auc: 0.9244548493250386\n",
      "Train pr_auc: 0.9082680072105116\n",
      "Train average_precision: 0.9082740352572781\n",
      "Val loss: 7.568815630014257\n",
      "Val accuracy: 0.5195043597980725\n",
      "Val precision: 0.9066985645933014\n",
      "Val recall: 0.0434832491968793\n",
      "Val f1: 0.08298664331070724\n",
      "Val roc_auc: 0.8314223566098102\n",
      "Val pr_auc: 0.7919497664980617\n",
      "Val average_precision: 0.7919846317883572\n",
      "Best val_f1: 0.28796465277110744\n",
      "\n",
      "Epoch 9\n",
      "Early stopping counter: 4\n",
      "Epoch Number: 9\n",
      "Epoch time: 40.58628273010254\n",
      "Train loss: 0.3192645033770369\n",
      "Train accuracy: 0.8633686919897043\n",
      "Train precision: 0.8476549382485729\n",
      "Train recall: 0.8859683332033382\n",
      "Train f1: 0.8663882691684305\n",
      "Train roc_auc: 0.9344905625198442\n",
      "Train pr_auc: 0.9171158665980801\n",
      "Train average_precision: 0.9171412303629722\n",
      "Val loss: 7.5434366828443284\n",
      "Val accuracy: 0.5138825149150986\n",
      "Val precision: 0.8954248366013072\n",
      "Val recall: 0.03143643873336393\n",
      "Val f1: 0.060740412325426735\n",
      "Val roc_auc: 0.8355310116319552\n",
      "Val pr_auc: 0.8002585315672759\n",
      "Val average_precision: 0.8002912987729903\n",
      "Best val_f1: 0.28796465277110744\n",
      "\n",
      "Epoch 10\n",
      "Early stopping counter: 5\n",
      "Early stopping triggered!\n",
      "Epoch Number: 10\n",
      "Epoch time: 40.8474497795105\n",
      "Train loss: 0.30836832330113934\n",
      "Train accuracy: 0.8690429763668981\n",
      "Train precision: 0.8537041190102415\n",
      "Train recall: 0.8907261524062086\n",
      "Train f1: 0.8718222765096572\n",
      "Train roc_auc: 0.9386577523453999\n",
      "Train pr_auc: 0.9208726627959329\n",
      "Train average_precision: 0.9208792777828322\n",
      "Val loss: 6.737597748795898\n",
      "Val accuracy: 0.5318379990821478\n",
      "Val precision: 0.8685258964143426\n",
      "Val recall: 0.07503441945846719\n",
      "Val f1: 0.13813496673355158\n",
      "Val roc_auc: 0.837378536748103\n",
      "Val pr_auc: 0.7973028104127322\n",
      "Val average_precision: 0.7973402348386065\n",
      "Best val_f1: 0.28796465277110744\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [00:24<00:00, 55.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test AUC: 0.8234\n",
      "Test AP: 0.8190\n",
      "Test F1: 0.5711\n",
      "Test Accuracy: 0.6833\n",
      "Test Precission: 0.8845\n",
      "Test Recall: 0.4217\n",
      "Test MCC: 0.4302\n",
      "Test MR: 9.3302\n",
      "Fold 3\n",
      "Device: 'cuda'\n",
      "Total Number of Parameters: 2744944\n",
      "Total Number of Trainable Parameters: 2744944\n",
      "Starting training loop at 2024-08-05 17:38:51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f149957d7d34b9c89ad6fef4235339d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MiniBatches:   0%|          | 0/6740 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "New best model saved!\n",
      "Epoch Number: 1\n",
      "Epoch time: 39.88079023361206\n",
      "Train loss: 1.1206484318076821\n",
      "Train accuracy: 0.7069066375477732\n",
      "Train precision: 0.7015537742658512\n",
      "Train recall: 0.7201856329459481\n",
      "Train f1: 0.7107476185894352\n",
      "Train roc_auc: 0.7618790022871729\n",
      "Train pr_auc: 0.7127700777777222\n",
      "Train average_precision: 0.7112217662249343\n",
      "Val loss: 27.516790300218858\n",
      "Val accuracy: 0.5122189077558513\n",
      "Val precision: 0.8338557993730408\n",
      "Val recall: 0.03051858650757228\n",
      "Val f1: 0.05888212506917542\n",
      "Val roc_auc: 0.7322533387980432\n",
      "Val pr_auc: 0.6887988015987283\n",
      "Val average_precision: 0.688899239199931\n",
      "Best val_f1: 0.05888212506917542\n",
      "\n",
      "Epoch 2\n",
      "New best model saved!\n",
      "Epoch Number: 2\n",
      "Epoch time: 39.24109148979187\n",
      "Train loss: 0.5504288887442496\n",
      "Train accuracy: 0.7864441151236253\n",
      "Train precision: 0.7834156505633585\n",
      "Train recall: 0.7917869120973403\n",
      "Train f1: 0.7875790372008223\n",
      "Train roc_auc: 0.86053962645777\n",
      "Train pr_auc: 0.8412033496351133\n",
      "Train average_precision: 0.8412136954114807\n",
      "Val loss: 13.469679809856867\n",
      "Val accuracy: 0.5262735199632859\n",
      "Val precision: 0.7197696737044146\n",
      "Val recall: 0.08604864616796695\n",
      "Val f1: 0.15372002459520395\n",
      "Val roc_auc: 0.7985185561266215\n",
      "Val pr_auc: 0.7360121032470469\n",
      "Val average_precision: 0.7360798762458871\n",
      "Best val_f1: 0.15372002459520395\n",
      "\n",
      "Epoch 3\n",
      "New best model saved!\n",
      "Epoch Number: 3\n",
      "Epoch time: 41.771265506744385\n",
      "Train loss: 0.47662522456146533\n",
      "Train accuracy: 0.8077958037594571\n",
      "Train precision: 0.8058041768375372\n",
      "Train recall: 0.8110521800171594\n",
      "Train f1: 0.8084196614254339\n",
      "Train roc_auc: 0.8834622647376604\n",
      "Train pr_auc: 0.8644959483832863\n",
      "Train average_precision: 0.8645065467672273\n",
      "Val loss: 3.9706987258397044\n",
      "Val accuracy: 0.5337884350619551\n",
      "Val precision: 0.7489433643279797\n",
      "Val recall: 0.10165213400642496\n",
      "Val f1: 0.17900798060410142\n",
      "Val roc_auc: 0.7877585329402169\n",
      "Val pr_auc: 0.7340389039008992\n",
      "Val average_precision: 0.7341144726150167\n",
      "Best val_f1: 0.17900798060410142\n",
      "\n",
      "Epoch 4\n",
      "Early stopping counter: 1\n",
      "Epoch Number: 4\n",
      "Epoch time: 40.67723536491394\n",
      "Train loss: 0.4226187723979094\n",
      "Train accuracy: 0.8251696435535449\n",
      "Train precision: 0.8175655088360756\n",
      "Train recall: 0.8371421885968333\n",
      "Train f1: 0.8272380438552546\n",
      "Train roc_auc: 0.8996896641443731\n",
      "Train pr_auc: 0.8819351370125802\n",
      "Train average_precision: 0.8819474340522693\n",
      "Val loss: 9.580432466139204\n",
      "Val accuracy: 0.5220284534189995\n",
      "Val precision: 0.8210702341137124\n",
      "Val recall: 0.056333180357962365\n",
      "Val f1: 0.10543268198410993\n",
      "Val roc_auc: 0.8195894764809318\n",
      "Val pr_auc: 0.7657173019369834\n",
      "Val average_precision: 0.7657728201256556\n",
      "Best val_f1: 0.17900798060410142\n",
      "\n",
      "Epoch 5\n",
      "Early stopping counter: 2\n",
      "Epoch Number: 5\n",
      "Epoch time: 40.359262228012085\n",
      "Train loss: 0.4130079104121486\n",
      "Train accuracy: 0.8295374775758522\n",
      "Train precision: 0.8198576727988492\n",
      "Train recall: 0.8446689025817019\n",
      "Train f1: 0.8320783711102574\n",
      "Train roc_auc: 0.9033318248998964\n",
      "Train pr_auc: 0.884074995484779\n",
      "Train average_precision: 0.8841036252321394\n",
      "Val loss: 4.385480229264091\n",
      "Val accuracy: 0.5162345112436898\n",
      "Val precision: 0.9054441260744985\n",
      "Val recall: 0.03625516291877008\n",
      "Val f1: 0.06971869829012688\n",
      "Val roc_auc: 0.7830764637984381\n",
      "Val pr_auc: 0.7356264974299908\n",
      "Val average_precision: 0.7356667692093294\n",
      "Best val_f1: 0.17900798060410142\n",
      "\n",
      "Epoch 6\n",
      "Early stopping counter: 3\n",
      "Epoch Number: 6\n",
      "Epoch time: 40.007322549819946\n",
      "Train loss: 0.3994215054627963\n",
      "Train accuracy: 0.8326183605023009\n",
      "Train precision: 0.823607527697678\n",
      "Train recall: 0.846540831448405\n",
      "Train f1: 0.8349167275664449\n",
      "Train roc_auc: 0.908566566078008\n",
      "Train pr_auc: 0.8917448681735151\n",
      "Train average_precision: 0.891753075941157\n",
      "Val loss: 6.426296043729603\n",
      "Val accuracy: 0.5278797613584213\n",
      "Val precision: 0.8283783783783784\n",
      "Val recall: 0.070330426801285\n",
      "Val f1: 0.12965313028764808\n",
      "Val roc_auc: 0.8204245577281241\n",
      "Val pr_auc: 0.76461574943994\n",
      "Val average_precision: 0.7646601036022246\n",
      "Best val_f1: 0.17900798060410142\n",
      "\n",
      "Epoch 7\n",
      "Early stopping counter: 4\n",
      "Epoch Number: 7\n",
      "Epoch time: 41.51082897186279\n",
      "Train loss: 0.3357215467236583\n",
      "Train accuracy: 0.856231963185399\n",
      "Train precision: 0.8429510043176272\n",
      "Train recall: 0.8755947274003588\n",
      "Train f1: 0.858962832603248\n",
      "Train roc_auc: 0.9292504587033008\n",
      "Train pr_auc: 0.9154263475453891\n",
      "Train average_precision: 0.9154325701870081\n",
      "Val loss: 2.811213547832737\n",
      "Val accuracy: 0.5160050481872418\n",
      "Val precision: 0.926605504587156\n",
      "Val recall: 0.03476365305185865\n",
      "Val f1: 0.0670131593497733\n",
      "Val roc_auc: 0.840585003899503\n",
      "Val pr_auc: 0.8156158383425997\n",
      "Val average_precision: 0.8156422673524457\n",
      "Best val_f1: 0.17900798060410142\n",
      "\n",
      "Epoch 8\n",
      "Early stopping counter: 5\n",
      "Early stopping triggered!\n",
      "Epoch Number: 8\n",
      "Epoch time: 39.554399728775024\n",
      "Train loss: 0.3264057699804591\n",
      "Train accuracy: 0.8610677794243818\n",
      "Train precision: 0.8472414957056595\n",
      "Train recall: 0.8809765228921301\n",
      "Train f1: 0.8637797533696588\n",
      "Train roc_auc: 0.9324779807419653\n",
      "Train pr_auc: 0.9163878050328755\n",
      "Train average_precision: 0.9163984072843394\n",
      "Val loss: 2.9647683599824557\n",
      "Val accuracy: 0.5272487379531895\n",
      "Val precision: 0.8740157480314961\n",
      "Val recall: 0.06367599816429555\n",
      "Val f1: 0.11870388193776066\n",
      "Val roc_auc: 0.8376680311416855\n",
      "Val pr_auc: 0.7941817649453875\n",
      "Val average_precision: 0.7942137427245058\n",
      "Best val_f1: 0.17900798060410142\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [00:25<00:00, 53.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test AUC: 0.7571\n",
      "Test AP: 0.7201\n",
      "Test F1: 0.5026\n",
      "Test Accuracy: 0.6267\n",
      "Test Precission: 0.7528\n",
      "Test Recall: 0.3772\n",
      "Test MCC: 0.2923\n",
      "Test MR: 9.0090\n"
     ]
    }
   ],
   "source": [
    "eval_metrics = train_wrap_cv(data, \"sdv-hgnn-variant-dv\", cv_fold=3, shuffle=True, \n",
    "                             num_neighbors=[10, 4], batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Standard Deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.801719</td>\n",
       "      <td>0.031582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ap</td>\n",
       "      <td>0.787321</td>\n",
       "      <td>0.047550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.576253</td>\n",
       "      <td>0.062373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>acc</td>\n",
       "      <td>0.676694</td>\n",
       "      <td>0.038439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.830204</td>\n",
       "      <td>0.056209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.443491</td>\n",
       "      <td>0.064889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>mr</td>\n",
       "      <td>9.698250</td>\n",
       "      <td>0.759048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mcc</td>\n",
       "      <td>0.399273</td>\n",
       "      <td>0.077853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric      Mean  Standard Deviation\n",
       "0        auc  0.801719            0.031582\n",
       "1         ap  0.787321            0.047550\n",
       "2         f1  0.576253            0.062373\n",
       "3        acc  0.676694            0.038439\n",
       "4  precision  0.830204            0.056209\n",
       "5     recall  0.443491            0.064889\n",
       "6         mr  9.698250            0.759048\n",
       "7        mcc  0.399273            0.077853"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = ['auc', 'ap', 'f1', 'acc', 'precision', 'recall', 'mr', 'mcc']\n",
    "metrics_mean_value = np.mean(eval_metrics, axis=0)\n",
    "metrics_std = np.std(eval_metrics, axis=0)\n",
    "df = pd.DataFrame({\n",
    "    'Metric': metrics,\n",
    "    'Mean': metrics_mean_value,\n",
    "    'Standard Deviation': metrics_std\n",
    "})\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sdv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
